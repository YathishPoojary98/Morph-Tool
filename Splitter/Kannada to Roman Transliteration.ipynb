{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd34780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ai4bharat-transliteration\n",
      "  Downloading ai4bharat_transliteration-1.1.3-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: ujson in /home/pranam/anaconda3/lib/python3.9/site-packages (from ai4bharat-transliteration) (5.4.0)\n",
      "Collecting gevent\n",
      "  Downloading gevent-22.10.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flask in /home/pranam/anaconda3/lib/python3.9/site-packages (from ai4bharat-transliteration) (1.1.2)\n",
      "Collecting fairseq\n",
      "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/pranam/anaconda3/lib/python3.9/site-packages (from ai4bharat-transliteration) (1.4.4)\n",
      "Requirement already satisfied: mock in /home/pranam/anaconda3/lib/python3.9/site-packages (from ai4bharat-transliteration) (4.0.3)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting indic-nlp-library\n",
      "  Downloading indic_nlp_library-0.81-py3-none-any.whl (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m623.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m281.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting flask-cors\n",
      "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tqdm in /home/pranam/anaconda3/lib/python3.9/site-packages (from ai4bharat-transliteration) (4.64.1)\n",
      "Collecting pydload\n",
      "  Downloading pydload-1.0.9-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyarrow in /home/pranam/anaconda3/lib/python3.9/site-packages (from ai4bharat-transliteration) (10.0.0)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting urduhack\n",
      "  Downloading urduhack-1.1.1-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.5/105.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m127.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/pranam/anaconda3/lib/python3.9/site-packages (from fairseq->ai4bharat-transliteration) (1.12.1)\n",
      "Requirement already satisfied: cffi in /home/pranam/anaconda3/lib/python3.9/site-packages (from fairseq->ai4bharat-transliteration) (1.15.1)\n",
      "Requirement already satisfied: cython in /home/pranam/anaconda3/lib/python3.9/site-packages (from fairseq->ai4bharat-transliteration) (0.29.32)\n",
      "Requirement already satisfied: bitarray in /home/pranam/anaconda3/lib/python3.9/site-packages (from fairseq->ai4bharat-transliteration) (2.5.1)\n",
      "Collecting hydra-core<1.1,>=1.0.7\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.1\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Collecting sacrebleu>=1.4.12\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio>=0.8.0\n",
      "  Downloading torchaudio-0.13.0-cp39-cp39-manylinux1_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex in /home/pranam/anaconda3/lib/python3.9/site-packages (from fairseq->ai4bharat-transliteration) (2022.7.9)\n",
      "Requirement already satisfied: numpy in /home/pranam/anaconda3/lib/python3.9/site-packages (from fairseq->ai4bharat-transliteration) (1.21.5)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/pranam/anaconda3/lib/python3.9/site-packages (from flask->ai4bharat-transliteration) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from flask->ai4bharat-transliteration) (8.0.4)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from flask->ai4bharat-transliteration) (2.11.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /home/pranam/anaconda3/lib/python3.9/site-packages (from flask->ai4bharat-transliteration) (2.0.3)\n",
      "Requirement already satisfied: Six in /home/pranam/anaconda3/lib/python3.9/site-packages (from flask-cors->ai4bharat-transliteration) (1.16.0)\n",
      "Requirement already satisfied: zope.interface in /home/pranam/anaconda3/lib/python3.9/site-packages (from gevent->ai4bharat-transliteration) (5.4.0)\n",
      "Collecting greenlet>=2.0.0\n",
      "  Downloading greenlet-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.0/533.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/pranam/anaconda3/lib/python3.9/site-packages (from gevent->ai4bharat-transliteration) (63.4.1)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.5.0-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting morfessor\n",
      "  Downloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Downloading sphinx_rtd_theme-1.1.0-py2.py3-none-any.whl (2.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting sphinx-argparse\n",
      "  Downloading sphinx_argparse-0.3.2-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from pandas->ai4bharat-transliteration) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from pandas->ai4bharat-transliteration) (2022.1)\n",
      "Collecting progressbar2\n",
      "  Downloading progressbar2-4.2.0-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: requests in /home/pranam/anaconda3/lib/python3.9/site-packages (from pydload->ai4bharat-transliteration) (2.28.1)\n",
      "Requirement already satisfied: joblib in /home/pranam/anaconda3/lib/python3.9/site-packages (from sacremoses->ai4bharat-transliteration) (1.1.0)\n",
      "Collecting protobuf<=3.20.1,>=3.8.0\n",
      "  Downloading protobuf-3.20.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-datasets~=3.1\n",
      "  Downloading tensorflow_datasets-3.2.1-py3-none-any.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting click>=5.1\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tf2crf\n",
      "  Downloading tf2crf-0.1.33-py2.py3-none-any.whl (7.3 kB)\n",
      "Collecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /home/pranam/anaconda3/lib/python3.9/site-packages (from Jinja2>=2.10.1->flask->ai4bharat-transliteration) (2.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.1.* in /home/pranam/anaconda3/lib/python3.9/site-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (6.0)\n",
      "Requirement already satisfied: typing-extensions in /home/pranam/anaconda3/lib/python3.9/site-packages (from omegaconf<2.1->fairseq->ai4bharat-transliteration) (4.3.0)\n",
      "Requirement already satisfied: lxml in /home/pranam/anaconda3/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (4.9.1)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (0.8.10)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in /home/pranam/anaconda3/lib/python3.9/site-packages (from sacrebleu>=1.4.12->fairseq->ai4bharat-transliteration) (0.4.5)\n",
      "Collecting promise\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill in /home/pranam/anaconda3/lib/python3.9/site-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (0.3.5.1)\n",
      "Requirement already satisfied: wrapt in /home/pranam/anaconda3/lib/python3.9/site-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (1.14.1)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.1.0-py3-none-any.whl (5.8 kB)\n",
      "Collecting absl-py\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.10.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m792.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: attrs>=18.1.0 in /home/pranam/anaconda3/lib/python3.9/site-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (21.4.0)\n",
      "Requirement already satisfied: future in /home/pranam/anaconda3/lib/python3.9/site-packages (from tensorflow-datasets~=3.1->urduhack->ai4bharat-transliteration) (0.18.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/pranam/anaconda3/lib/python3.9/site-packages (from requests->pydload->ai4bharat-transliteration) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/pranam/anaconda3/lib/python3.9/site-packages (from requests->pydload->ai4bharat-transliteration) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from requests->pydload->ai4bharat-transliteration) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/pranam/anaconda3/lib/python3.9/site-packages (from requests->pydload->ai4bharat-transliteration) (2022.9.14)\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp39-cp39-manylinux1_x86_64.whl (890.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.2/890.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /home/pranam/anaconda3/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->fairseq->ai4bharat-transliteration) (0.37.1)\n",
      "Requirement already satisfied: pycparser in /home/pranam/anaconda3/lib/python3.9/site-packages (from cffi->fairseq->ai4bharat-transliteration) (2.21)\n",
      "Collecting python-utils>=3.0.0\n",
      "  Downloading python_utils-3.4.5-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: sphinx>=1.2.0 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (5.0.2)\n",
      "Collecting docutils<0.18\n",
      "  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-addons>=0.8.2\n",
      "  Downloading tensorflow_addons-0.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow>=2.1.0\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (21.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (4.11.3)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.2.0)\n",
      "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.0.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (0.7.12)\n",
      "Requirement already satisfied: imagesize in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.4.1)\n",
      "Requirement already satisfied: babel>=1.3 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.9.1)\n",
      "Requirement already satisfied: sphinxcontrib-devhelp in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (2.11.2)\n",
      "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.1.5)\n",
      "Requirement already satisfied: sphinxcontrib-qthelp in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.3)\n",
      "Requirement already satisfied: sphinxcontrib-jsmath in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.1)\n",
      "Requirement already satisfied: sphinxcontrib-applehelp in /home/pranam/anaconda3/lib/python3.9/site-packages (from sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (1.0.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/pranam/anaconda3/lib/python3.9/site-packages (from tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (3.7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m643.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m108.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.20.1,>=3.8.0\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m856.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.50.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m989.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting googleapis-common-protos<2,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m574.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m119.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /home/pranam/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (3.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/pranam/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (3.3.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.14.0-py2.py3-none-any.whl (175 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.0/175.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pranam/anaconda3/lib/python3.9/site-packages (from packaging->sphinx>=1.2.0->sphinx-argparse->indic-nlp-library->ai4bharat-transliteration) (3.0.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/pranam/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/pranam/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow>=2.1.0->tf2crf->urduhack->ai4bharat-transliteration) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m109.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: fairseq, sacremoses, antlr4-python3-runtime, promise\n",
      "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp39-cp39-linux_x86_64.whl size=10394472 sha256=31d08b9680e81fd03aa1597a4d476c75fac1168f0e83d21a836cd3e9cf8657eb\n",
      "  Stored in directory: /home/pranam/.cache/pip/wheels/59/35/87/2baf2e4ad37c83fd698c486b3d39f0e7022226fa52ab469c31\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=7e393936dfed4885eea848b2ba374f4b8a49f020416e3c438ae3e06f65ebf722\n",
      "  Stored in directory: /home/pranam/.cache/pip/wheels/12/1c/3d/46cf06718d63a32ff798a89594b61e7f345ab6b36d909ce033\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=0110b5a0951eb4c0c1a9474c556fa8c39262c4bc857a81a28bc891b068d21b75\n",
      "  Stored in directory: /home/pranam/.cache/pip/wheels/42/3c/ae/14db087e6018de74810afe32eb6ac890ef9c68ba19b00db97a\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=be515dbe1ca3869afe4902623bfc90b9f11c4fd7d2811feec79789fadc6734ec\n",
      "  Stored in directory: /home/pranam/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
      "Successfully built fairseq sacremoses antlr4-python3-runtime promise\n",
      "Installing collected packages: tensorboard-plugin-wit, morfessor, libclang, keras, flatbuffers, antlr4-python3-runtime, zope.event, typeguard, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, python-utils, protobuf, promise, portalocker, opt-einsum, omegaconf, oauthlib, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, keras-preprocessing, grpcio, greenlet, google-pasta, gast, docutils, click, cachetools, astunparse, absl-py, tensorflow-addons, tensorboardX, sacremoses, sacrebleu, requests-oauthlib, progressbar2, nvidia-cudnn-cu11, hydra-core, googleapis-common-protos, google-auth, gevent, torch, tensorflow-metadata, sphinx-rtd-theme, sphinx-argparse, pydload, google-auth-oauthlib, flask-cors, torchaudio, tensorflow-datasets, tensorboard, indic-nlp-library, tensorflow, fairseq, tf2crf, urduhack, ai4bharat-transliteration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.1.1\n",
      "    Uninstalling greenlet-1.1.1:\n",
      "      Successfully uninstalled greenlet-1.1.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.18.1\n",
      "    Uninstalling docutils-0.18.1:\n",
      "      Successfully uninstalled docutils-0.18.1\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.1\n",
      "    Uninstalling torch-1.12.1:\n",
      "      Successfully uninstalled torch-1.12.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
      "black 22.6.0 requires click>=8.0.0, but you have click 7.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.3.0 ai4bharat-transliteration-1.1.3 antlr4-python3-runtime-4.8 astunparse-1.6.3 cachetools-5.2.0 click-7.1.2 docutils-0.17.1 fairseq-0.12.2 flask-cors-3.0.10 flatbuffers-22.10.26 gast-0.4.0 gevent-22.10.2 google-auth-2.14.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.56.4 greenlet-2.0.0 grpcio-1.50.0 hydra-core-1.0.7 indic-nlp-library-0.81 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 morfessor-2.0.6 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 oauthlib-3.2.2 omegaconf-2.0.6 opt-einsum-3.3.0 portalocker-2.6.0 progressbar2-4.2.0 promise-2.3 protobuf-3.19.6 pydload-1.0.9 python-utils-3.4.5 requests-oauthlib-1.3.1 rsa-4.9 sacrebleu-2.3.1 sacremoses-0.0.53 sphinx-argparse-0.3.2 sphinx-rtd-theme-1.1.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorboardX-2.5.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-datasets-3.2.1 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 tensorflow-metadata-1.10.0 termcolor-2.1.0 tf2crf-0.1.33 torch-1.13.0 torchaudio-0.13.0 typeguard-2.13.3 urduhack-1.1.1 zope.event-4.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ai4bharat-transliteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc749b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai4bharat.transliteration import XlitEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a98afdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 11:18:43.475597: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-02 11:18:43.674703: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-02 11:18:43.713024: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-02 11:18:46.521162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-02 11:18:46.521278: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-02 11:18:46.521292: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pranam/anaconda3/lib/python3.9/site-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Loading dicts into RAM: 100%|█████████████████████| 1/1 [00:01<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hi': ['नमस्ते', 'नमस्थे', 'नामस्थे', 'नमास्थे', 'नमस्थें']}\n"
     ]
    }
   ],
   "source": [
    "e = XlitEngine(\"hi\", beam_width=10, rescore=True)\n",
    "out = e.translit_word(\"namasthe\", topk=5)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d427bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Multilingual model for transliteration\n",
      "['maharshi', 'mahrishi', 'maharishi', 'mahershi', 'maharshee']\n"
     ]
    }
   ],
   "source": [
    "e = XlitEngine(src_script_type=\"indic\", beam_width=10, rescore=False)\n",
    "out = e.translit_word(\"ಮಹರ್ಷಿ\", lang_code=\"kn\", topk=5)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2a0cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.21.5\n",
      "Uninstalling numpy-1.21.5:\n",
      "  Successfully uninstalled numpy-1.21.5\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "Installing collected packages: numpy\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.6.0 requires daal==2021.4.0, which is not installed.\n",
      "torchvision 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
      "numba 0.55.1 requires numpy<1.22,>=1.18, but you have numpy 1.23.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall numpy -y\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6be93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
